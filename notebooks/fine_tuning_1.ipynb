{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddef2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ed0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/raw/counsel_chat.csv\")\n",
    "df = pd.read_csv(\"hf://datasets/nbertagnolli/counsel-chat/20220401_counsel_chat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f1d965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "questionID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "questionTitle",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "questionText",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "questionLink",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "therapistInfo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "therapistURL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answerText",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "upvotes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "views",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "89600f8c-acf9-4c34-b450-07fa4d45ae79",
       "rows": [
        [
         "1948",
         "685",
         "Where does a child go for help?",
         "I'm having issues with my relative. The police never believe the experiences I have been through because I am only a kid. \n   I've even had trouble trying to reach a therapist because I said I wanted to get an adult to help me. Could you please give me advice?",
         "https://counselchat.com/questions/where-does-a-child-go-for-help",
         "family-conflict",
         "Danielle AlvarezLicensed Professional Counselor",
         "https://counselchat.com/therapists/danielle-alvarez",
         "I think it would be wise for you to call a hotline especially designed for children. It's called the Childhelp National Child Abuse Hotline. The number is 1-800-4-A-CHILD (1-800-422-4453). It is completely anonymous and a trained therapist will be able to provide you with guidance, confidentiality, and can also help you make a report of you want.The call is completely free and they are open 24 hours a day / 7 days a week. I'm glad that you are taking steps to improve your situation. You are a very brave and an intelligent child. Please remember to call 911 if you are in immediate danger.",
         "1",
         "135"
        ],
        [
         "284",
         "35",
         "Do I have anxiety?",
         "I stress over everything. If I don't have enough \"quality time\" with my boyfriend, I start to feel resentment towards him. He has three children, and they are great kids, but I find we don't have much time together. I break down easily and find myself depressed.",
         "https://counselchat.com/questions/do-i-have-anxiety",
         "depression",
         "Kaileen McMickle, MS, LPCLicensed Professional Counselor",
         "https://counselchat.com/therapists/kaileen-mcmickle-ms-lpc",
         "Feeling neglected in a romantic relationship can be pretty painful, so I don't think your response is anything out of the ordinary.  I do wonder what you mean when you say you stress over everything and break down easily.  Is that according to your own assessments or someone else's?  What do those moments look like?  Within the context of a lot of stress, breaking down wouldn't take a whole lot---and it's OK to break down.  It's the body's way of releasing pent up emotions.  If that's coming out via aggression or self-harm, it may be time well spent to create a coping plan for those tough times in order to feel like you have more control over your default response.Sometimes voicing your needs can help people to meet them, or at least compromise.  If you feel he would be receptive to a discussion, let him know how much time you need a day, or week.  You may not even fully know that, but if he's flexible, you can test out what feels right for your relationship.",
         "0",
         "94"
        ],
        [
         "1387",
         "430",
         "How can I get therapy for posttraumatic stress disorder without any money or insurance?",
         null,
         "https://counselchat.com/questions/how-can-i-get-therapy-for-posttraumatic-stress-disorder-without-any-money-or-insurance",
         "trauma",
         "Candice Conroy, LMHCFind relief from anxiety, depression, and trauma.",
         "https://counselchat.com/therapists/candice-conroy-lmhc",
         "Depending on where you are located, you may want to consider calling 2-1-1. It is a resource hotline that can help provide you with referrals for therapists or clinics in your area who may offer pro-bono services. When going through the list of referrals they provide you with, you can call around and see what types of treatment they offer for PTSD and make a list so you can do your own research before deciding what you think will be the best fit for you. There are several different types of trauma therapy, but some of the most common include cognitive processing therapy and EMDR in case you'd like to research them and get more information.",
         "1",
         "164"
        ],
        [
         "2087",
         "728",
         "My boyfriend is upset about my friendship with another guy",
         "I have a friend that who I used to be in a relationship with. It was brief and turned into us being just good friends.\n   I spent the weekend with him and it upset my boyfriend. Was i wrong?",
         "https://counselchat.com/questions/my-boyfriend-is-upset-about-my-friendship-with-another-guy",
         "relationships",
         "Anna McElearneyHelping Couples Build Stronger Relationships",
         "https://counselchat.com/therapists/anna-mcelearney",
         "Thank you for submitting this question. I think this type of situation can be common for many couples struggling with how to keep friendships with past relationships while being in a new relationship. For me, more information is needed here...but given the information provided, the way I interpret the question is...I'm assuming your boyfriend didn't know you were going to spend the weekend with your good friend?  Working off of this assumption, I would suggest beginning an open and honest dialogue with your boyfriend about what specifically upset him? And to talk about your point of view regarding spending the weekend with him. I would also suggest talking about how you both envision your relationship when it comes to spending time with others. If you feel like you can't have this conversation without it going off track, please consider seeing a couples therapist. They can help you begin these important conversations that can help shape and develop the relationship you and your boyfriend long for.",
         "0",
         "277"
        ],
        [
         "96",
         "4",
         "How can I help my girlfriend?",
         "My girlfriend just quit drinking and she became really depressed. She told me that she wants to move. What can I do to help her? I want her to stay.",
         "https://counselchat.com/questions/how-can-i-help-my-girlfriend",
         "depression",
         "Kristi King-Morgan, LMSWSocial Worker, Psychotherapist",
         "https://counselchat.com/therapists/kristi-king-morgan-lmsw",
         "You're probably not going to like my answer.Your question says a lot about what YOU want rather than what she wants or what may be best for her. Sometimes, what's best for a person is the hardest thing to do, and may be completely opposite of what YOU want.Addictions don't happen in a vacuum. If you've had any experience with addicts at all, then I'm sure you've heard the term \"enabler\". A lot of the times, when people think they're \"helping\", they're actually enabling the addict to continue their self-destructive behavior. Tough love and clear boundaries are needed in a lot of situations, but especially with addictions. Family and friends are often the biggest contributing factor to someone choosing to use/drink, continuing to do so, or relapsing back into it.You said she recently quit. You said she is depressed. She wants to move. When a person receives counseling for addictions, they are encouraged to make changes like this. They need to break the habit, and this means removing people from their lives at times. It means moving to new locations. Anything that may trigger a relapse needs to be identified and removed. Not only that, but the addict needs to do a lot of personal reflection to figure out WHY they use/drink in the first place, and not only break the physical addiction to it, but deal with whatever is the root cause that led them to use in the first place. She may need some time alone to figure out who she is as a person, time to make some decisions for herself and do what she needs to do to be healthy.Don't pressure her to stay. Let her have the freedom to do what she needs to do. If she stays, the decision needs to be hers and hers alone. It doesn't need to be made under pressure. That will only lead to resentment. Support her, but don't try to change her or make her do anything, especially for selfish reasons. Let her go. It sounds like she needs some time to focus on herself right now. It wouldn't be a bad idea for you to do the same.",
         "3",
         "824"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionID</th>\n",
       "      <th>questionTitle</th>\n",
       "      <th>questionText</th>\n",
       "      <th>questionLink</th>\n",
       "      <th>topic</th>\n",
       "      <th>therapistInfo</th>\n",
       "      <th>therapistURL</th>\n",
       "      <th>answerText</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>685</td>\n",
       "      <td>Where does a child go for help?</td>\n",
       "      <td>I'm having issues with my relative. The police...</td>\n",
       "      <td>https://counselchat.com/questions/where-does-a...</td>\n",
       "      <td>family-conflict</td>\n",
       "      <td>Danielle AlvarezLicensed Professional Counselor</td>\n",
       "      <td>https://counselchat.com/therapists/danielle-al...</td>\n",
       "      <td>I think it would be wise for you to call a hot...</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>35</td>\n",
       "      <td>Do I have anxiety?</td>\n",
       "      <td>I stress over everything. If I don't have enou...</td>\n",
       "      <td>https://counselchat.com/questions/do-i-have-an...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Kaileen McMickle, MS, LPCLicensed Professional...</td>\n",
       "      <td>https://counselchat.com/therapists/kaileen-mcm...</td>\n",
       "      <td>Feeling neglected in a romantic relationship c...</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>430</td>\n",
       "      <td>How can I get therapy for posttraumatic stress...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://counselchat.com/questions/how-can-i-ge...</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Candice Conroy, LMHCFind relief from anxiety, ...</td>\n",
       "      <td>https://counselchat.com/therapists/candice-con...</td>\n",
       "      <td>Depending on where you are located, you may wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>728</td>\n",
       "      <td>My boyfriend is upset about my friendship with...</td>\n",
       "      <td>I have a friend that who I used to be in a rel...</td>\n",
       "      <td>https://counselchat.com/questions/my-boyfriend...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Anna McElearneyHelping Couples Build Stronger ...</td>\n",
       "      <td>https://counselchat.com/therapists/anna-mcelea...</td>\n",
       "      <td>Thank you for submitting this question. I thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>How can I help my girlfriend?</td>\n",
       "      <td>My girlfriend just quit drinking and she becam...</td>\n",
       "      <td>https://counselchat.com/questions/how-can-i-he...</td>\n",
       "      <td>depression</td>\n",
       "      <td>Kristi King-Morgan, LMSWSocial Worker, Psychot...</td>\n",
       "      <td>https://counselchat.com/therapists/kristi-king...</td>\n",
       "      <td>You're probably not going to like my answer.Yo...</td>\n",
       "      <td>3</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      questionID                                      questionTitle  \\\n",
       "1948         685                    Where does a child go for help?   \n",
       "284           35                                 Do I have anxiety?   \n",
       "1387         430  How can I get therapy for posttraumatic stress...   \n",
       "2087         728  My boyfriend is upset about my friendship with...   \n",
       "96             4                      How can I help my girlfriend?   \n",
       "\n",
       "                                           questionText  \\\n",
       "1948  I'm having issues with my relative. The police...   \n",
       "284   I stress over everything. If I don't have enou...   \n",
       "1387                                                NaN   \n",
       "2087  I have a friend that who I used to be in a rel...   \n",
       "96    My girlfriend just quit drinking and she becam...   \n",
       "\n",
       "                                           questionLink            topic  \\\n",
       "1948  https://counselchat.com/questions/where-does-a...  family-conflict   \n",
       "284   https://counselchat.com/questions/do-i-have-an...       depression   \n",
       "1387  https://counselchat.com/questions/how-can-i-ge...           trauma   \n",
       "2087  https://counselchat.com/questions/my-boyfriend...    relationships   \n",
       "96    https://counselchat.com/questions/how-can-i-he...       depression   \n",
       "\n",
       "                                          therapistInfo  \\\n",
       "1948    Danielle AlvarezLicensed Professional Counselor   \n",
       "284   Kaileen McMickle, MS, LPCLicensed Professional...   \n",
       "1387  Candice Conroy, LMHCFind relief from anxiety, ...   \n",
       "2087  Anna McElearneyHelping Couples Build Stronger ...   \n",
       "96    Kristi King-Morgan, LMSWSocial Worker, Psychot...   \n",
       "\n",
       "                                           therapistURL  \\\n",
       "1948  https://counselchat.com/therapists/danielle-al...   \n",
       "284   https://counselchat.com/therapists/kaileen-mcm...   \n",
       "1387  https://counselchat.com/therapists/candice-con...   \n",
       "2087  https://counselchat.com/therapists/anna-mcelea...   \n",
       "96    https://counselchat.com/therapists/kristi-king...   \n",
       "\n",
       "                                             answerText  upvotes  views  \n",
       "1948  I think it would be wise for you to call a hot...        1    135  \n",
       "284   Feeling neglected in a romantic relationship c...        0     94  \n",
       "1387  Depending on where you are located, you may wa...        1    164  \n",
       "2087  Thank you for submitting this question. I thin...        0    277  \n",
       "96    You're probably not going to like my answer.Yo...        3    824  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e843de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"questionText\", \"topic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748ef2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d7dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={\"questionText\": \"question\", \"topic\": \"answer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3f4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 865 entries, 0 to 2769\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  865 non-null    object\n",
      " 1   answer    865 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 20.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0374ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "044fb29c-fc8a-4d88-85a4-6c858403bd22",
       "rows": [
        [
         "depression",
         "137"
        ],
        [
         "intimacy",
         "108"
        ],
        [
         "relationships",
         "104"
        ],
        [
         "anxiety",
         "100"
        ],
        [
         "family-conflict",
         "60"
        ],
        [
         "parenting",
         "54"
        ],
        [
         "self-esteem",
         "42"
        ],
        [
         "relationship-dissolution",
         "33"
        ],
        [
         "behavioral-change",
         "31"
        ],
        [
         "anger-management",
         "26"
        ],
        [
         "trauma",
         "24"
        ],
        [
         "marriage",
         "20"
        ],
        [
         "domestic-violence",
         "16"
        ],
        [
         "lgbtq",
         "15"
        ],
        [
         "social-relationships",
         "12"
        ],
        [
         "workplace-relationships",
         "11"
        ],
        [
         "substance-abuse",
         "10"
        ],
        [
         "grief-and-loss",
         "9"
        ],
        [
         "counseling-fundamentals",
         "7"
        ],
        [
         "spirituality",
         "7"
        ],
        [
         "professional-ethics",
         "6"
        ],
        [
         "legal-regulatory",
         "6"
        ],
        [
         "eating-disorders",
         "5"
        ],
        [
         "sleep-improvement",
         "5"
        ],
        [
         "addiction",
         "4"
        ],
        [
         "human-sexuality",
         "4"
        ],
        [
         "stress",
         "3"
        ],
        [
         "diagnosis",
         "3"
        ],
        [
         "children-adolescents",
         "2"
        ],
        [
         "military-issues",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 30
       }
      },
      "text/plain": [
       "answer\n",
       "depression                  137\n",
       "intimacy                    108\n",
       "relationships               104\n",
       "anxiety                     100\n",
       "family-conflict              60\n",
       "parenting                    54\n",
       "self-esteem                  42\n",
       "relationship-dissolution     33\n",
       "behavioral-change            31\n",
       "anger-management             26\n",
       "trauma                       24\n",
       "marriage                     20\n",
       "domestic-violence            16\n",
       "lgbtq                        15\n",
       "social-relationships         12\n",
       "workplace-relationships      11\n",
       "substance-abuse              10\n",
       "grief-and-loss                9\n",
       "counseling-fundamentals       7\n",
       "spirituality                  7\n",
       "professional-ethics           6\n",
       "legal-regulatory              6\n",
       "eating-disorders              5\n",
       "sleep-improvement             5\n",
       "addiction                     4\n",
       "human-sexuality               4\n",
       "stress                        3\n",
       "diagnosis                     3\n",
       "children-adolescents          2\n",
       "military-issues               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"answer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66369ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "331af3ae-7850-4258-9518-2837c947bd55",
       "rows": [
        [
         "0",
         "I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\n   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?",
         "depression"
        ],
        [
         "86",
         "I have been diagnosed with general anxiety and depression by my family doctor. They wrote a prescription for me to have an emotional support dog, I have the paper work, and I gave it to my apartment manager. They said I can't keep the ESD because I'm not disabled. What do you suggest I do?",
         "depression"
        ],
        [
         "91",
         "My mother is combative with me when I say I don't want to talk with her about my depression.    She hasn't been supportive of me in the past and she isn't someone that I feel comfortable opening up to. She constantly tries to instigate conversations where she asks me questions that I don't want to or can't answer. I tell her I don't want to talk and she starts arguments with me.    How can I get her to understand?",
         "depression"
        ],
        [
         "93",
         "There are many people willing to lovingly provide me with a home. I have food, clothes, and a university education, but I never feel like I belong. Even when I have a good time with people who are supposed to be close, I feel like I'm just out with friends and I never go home.",
         "depression"
        ],
        [
         "96",
         "My girlfriend just quit drinking and she became really depressed. She told me that she wants to move. What can I do to help her? I want her to stay.",
         "depression"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>I have been diagnosed with general anxiety and...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>My mother is combative with me when I say I do...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>There are many people willing to lovingly prov...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My girlfriend just quit drinking and she becam...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question      answer\n",
       "0   I have so many issues to address. I have a his...  depression\n",
       "86  I have been diagnosed with general anxiety and...  depression\n",
       "91  My mother is combative with me when I say I do...  depression\n",
       "93  There are many people willing to lovingly prov...  depression\n",
       "96  My girlfriend just quit drinking and she becam...  depression"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c1df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_qwen_chatml(df, tokenizer_name, max_length=512):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    processed = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        instruction = row[\"question\"]\n",
    "        response = row[\"answer\"]\n",
    "\n",
    "        chat_prompt = (\n",
    "            \"<|im_start|>system\\n\"\n",
    "            \"You are a mental health assistant. Based on the user's description, respond with a single sentence indicating the most relevant diagnosis from the mental health domain.<|im_end|>\\n\"\n",
    "            f\"<|im_start|>user\\n{instruction}<|im_end|>\\n\"\n",
    "            f\"<|im_start|>assistant\\nBased on what you've described, this sounds like {response}.<|im_end|>\"\n",
    "        )\n",
    "\n",
    "        # Tokenize full prompt\n",
    "        tokenized = tokenizer(chat_prompt, truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "\n",
    "        # Mask everything before assistant's response in labels\n",
    "        assistant_start = chat_prompt.find(\"<|im_start|>assistant\")\n",
    "        response_start = tokenizer(chat_prompt[:assistant_start], truncation=True, max_length=max_length, padding=\"max_length\")[\"input_ids\"]\n",
    "        labels = tokenized[\"input_ids\"].copy()\n",
    "        labels[:len(response_start)] = [-100] * len(response_start)\n",
    "\n",
    "        processed.append({\n",
    "            \"chat_prompt\": chat_prompt,\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"labels\": labels\n",
    "        })\n",
    "\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd2b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ebf15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen1.5-0.5B-Chat\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=device\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B-Chat\", use_fast=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "458557fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "chatbot = pipeline(\"text-generation\", model=\n",
    "                   model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "462a7c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The most relevant diagnosis from the mental health domain is suicide.\n"
     ]
    }
   ],
   "source": [
    "issue = \"\"\"<|im_start|>system\\n\"\n",
    "\"You are a mental health assistant. Based on the user's description, respond with a single sentence indicating the most relevant diagnosis from the mental health domain.<|im_end|>\\n\"\n",
    "<|im_start|>user\n",
    "I am broke and I want to kill myself<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "response = chatbot(issue, max_new_tokens=100, do_sample=True, temperature=0.7)\n",
    "generated = response[0]['generated_text']\n",
    "assistant_start = generated.find(\"<|im_start|>assistant\\n\") + len(\"<|im_start|>assistant\\n\")\n",
    "reply = generated[assistant_start:].strip().split(\"<|im_end|>\")[0].strip()\n",
    "print(\"Assistant:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31d07531",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(df[[\"question\", \"answer\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed6e8ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbd65f0a1a54ef79897cb3a3ccb3dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/865 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = hf_dataset.map(lambda ex: preprocess_qwen_chatml(pd.DataFrame([ex]), \"Qwen/Qwen1.5-0.5B-Chat\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0703485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'I have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\\n   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?',\n",
       " 'answer': 'depression',\n",
       " '__index_level_0__': 0,\n",
       " 'chat_prompt': \"You are a compassionate therapist. Given a patient's description, respond with empathy and insight based on their concerns.<|im_end|>\\n<|im_start|>user\\nI have so many issues to address. I have a history of sexual abuse, I’m a breast cancer survivor and I am a lifetime insomniac.    I have a long history of depression and I’m beginning to have anxiety. I have low self esteem but I’ve been happily married for almost 35 years.\\n   I’ve never had counseling about any of this. Do I have too many issues to address in counseling?<|im_end|>\\n<|im_start|>assistant\\nBased on what you've described, this sounds like depression.<|im_end|>\",\n",
       " 'input_ids': [2610,\n",
       "  525,\n",
       "  264,\n",
       "  59861,\n",
       "  41763,\n",
       "  13,\n",
       "  16246,\n",
       "  264,\n",
       "  8720,\n",
       "  594,\n",
       "  4008,\n",
       "  11,\n",
       "  5889,\n",
       "  448,\n",
       "  47351,\n",
       "  323,\n",
       "  20017,\n",
       "  3118,\n",
       "  389,\n",
       "  862,\n",
       "  10520,\n",
       "  13,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  872,\n",
       "  198,\n",
       "  40,\n",
       "  614,\n",
       "  773,\n",
       "  1657,\n",
       "  4714,\n",
       "  311,\n",
       "  2621,\n",
       "  13,\n",
       "  358,\n",
       "  614,\n",
       "  264,\n",
       "  3840,\n",
       "  315,\n",
       "  7244,\n",
       "  11480,\n",
       "  11,\n",
       "  358,\n",
       "  4249,\n",
       "  264,\n",
       "  17216,\n",
       "  9387,\n",
       "  48648,\n",
       "  323,\n",
       "  358,\n",
       "  1079,\n",
       "  264,\n",
       "  19031,\n",
       "  1640,\n",
       "  316,\n",
       "  7751,\n",
       "  580,\n",
       "  13,\n",
       "  262,\n",
       "  358,\n",
       "  614,\n",
       "  264,\n",
       "  1293,\n",
       "  3840,\n",
       "  315,\n",
       "  18210,\n",
       "  323,\n",
       "  358,\n",
       "  4249,\n",
       "  7167,\n",
       "  311,\n",
       "  614,\n",
       "  18056,\n",
       "  13,\n",
       "  358,\n",
       "  614,\n",
       "  3347,\n",
       "  656,\n",
       "  84497,\n",
       "  714,\n",
       "  358,\n",
       "  3982,\n",
       "  1012,\n",
       "  36775,\n",
       "  12224,\n",
       "  369,\n",
       "  4558,\n",
       "  220,\n",
       "  18,\n",
       "  20,\n",
       "  1635,\n",
       "  624,\n",
       "  256,\n",
       "  358,\n",
       "  3982,\n",
       "  2581,\n",
       "  1030,\n",
       "  41216,\n",
       "  911,\n",
       "  894,\n",
       "  315,\n",
       "  419,\n",
       "  13,\n",
       "  3155,\n",
       "  358,\n",
       "  614,\n",
       "  2238,\n",
       "  1657,\n",
       "  4714,\n",
       "  311,\n",
       "  2621,\n",
       "  304,\n",
       "  41216,\n",
       "  30,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  77091,\n",
       "  198,\n",
       "  28715,\n",
       "  389,\n",
       "  1128,\n",
       "  498,\n",
       "  3003,\n",
       "  7481,\n",
       "  11,\n",
       "  419,\n",
       "  10362,\n",
       "  1075,\n",
       "  18210,\n",
       "  13,\n",
       "  151645,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [-100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee55fa4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f110bc2249f249c9b0d958efea975cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/865 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the processed dataset\n",
    "tokenized_dataset.save_to_disk(\"../data/processed/qwen_chatml_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893ee6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the processed dataset\n",
    "tokenized_dataset = Dataset.load_from_disk(\"../data/processed/qwen_chatml_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a7b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:2243: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of 🤗 Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='651' max='651' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [651/651 05:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.822400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.610300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.584500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.520500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=651, training_loss=1.8837883710494971, metrics={'train_runtime': 352.4117, 'train_samples_per_second': 7.364, 'train_steps_per_second': 1.847, 'total_flos': 2464826602291200.0, 'train_loss': 1.8837883710494971, 'epoch': 3.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned-model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    use_mps_device=True,\n",
    "    label_names=[\"labels\"],  # Explicitly specify label names for PEFT models\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "peft_model_id = \"./finetuned-model/checkpoint-651\"\n",
    "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(peft_config.base_model_name_or_path, return_dict=True)\n",
    "\n",
    "# Load adapter into base model\n",
    "model = PeftModel.from_pretrained(base_model, peft_model_id)\n",
    "\n",
    "# Merge LoRA weights into base model\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "merged_model.save_pretrained(\"./finetuned-model/merged\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "tokenizer.save_pretrained(\"./finetuned-model/merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd58c3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./finetuned-model/merged/tokenizer_config.json',\n",
       " './finetuned-model/merged/special_tokens_map.json',\n",
       " './finetuned-model/merged/chat_template.jinja',\n",
       " './finetuned-model/merged/vocab.json',\n",
       " './finetuned-model/merged/merges.txt',\n",
       " './finetuned-model/merged/added_tokens.json',\n",
       " './finetuned-model/merged/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)\n",
    "tokenizer.save_pretrained(\"./finetuned-model/merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc51423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "tuned_model = AutoModelForCausalLM.from_pretrained(\"./finetuned-model/merged\", torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./finetuned-model/merged\", use_fast=True, trust_remote_code=True)\n",
    "\n",
    "chatbot = pipeline(\"text-generation\", model=tuned_model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Based on what you've described, this sounds like depression.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "issue = \"\"\"<|im_start|>system\\n\"\n",
    "\"You are a mental health assistant. Based on the user's description, respond with a single sentence indicating the most relevant diagnosis from the mental health domain.<|im_end|>\\n\"\n",
    "<|im_start|>user\n",
    "I am broke and I want to kill myself<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "response = chatbot(issue, max_new_tokens=100, do_sample=True, temperature=0.7)\n",
    "generated = response[0]['generated_text']\n",
    "assistant_start = generated.find(\"<|im_start|>assistant\\n\") + len(\"<|im_start|>assistant\\n\")\n",
    "reply = generated[assistant_start:].strip().split(\"<|im_end|>\")[0].strip()\n",
    "print(\"Assistant:\", reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74c9f37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1582c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "checkpoints = sorted(Path(\"./finetuned-model\").glob(\n",
    "    \"checkpoint-*\"), key=os.path.getmtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "842bf6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('finetuned-model/checkpoint-500'),\n",
       " PosixPath('finetuned-model/checkpoint-651')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "147e1728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finetuned-model/checkpoint-651'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(checkpoints[-1]) if checkpoints else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d8796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
